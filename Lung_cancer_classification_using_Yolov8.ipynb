{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAcKaPQVcw5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daac709-0d69-4496-87f2-53d66556d335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 14 15:25:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0dx0mfRfzoM",
        "outputId": "5b65aacf-98c4-41de-a00e-9dbbeed0478e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 25.5/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1hlOUh8DktTV4UeH0Wl8\")\n",
        "project = rf.workspace(\"satyam-mishra-gfl0c\").project(\"lung-cancer-detection-afeuf\")\n",
        "dataset = project.version(1).download(\"folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "igFiRpY9WBrI",
        "outputId": "0e5cc41b-923a-4504-bac7-31292451a2da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.26.15)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (8.4.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.65.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (4.39.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (23.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9673 sha256=f8e1224ac7815c5b36fa4a976dd5a39330c9bcd3b20e348cf1e79dcf6800a41d\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-0.10.1 roboflow-1.0.1 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Lung-cancer-detection-1 to folder: 100% [22327345 / 22327345] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Lung-cancer-detection-1 in folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2654/2654 [00:00<00:00, 3205.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=train model=yolov8n-cls.pt data={dataset.location} epochs=100 imgsz=224 single_cls=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH9cTx6KuqtG",
        "outputId": "f2a0e062-4088-4555-f903-158aeafd82e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to yolov8n-cls.pt...\n",
            "100% 5.28M/5.28M [00:00<00:00, 19.9MB/s]\n",
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/Lung-cancer-detection-1, epochs=100, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=True, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "Overriding model.yaml nc=1000 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    336645  ultralytics.nn.modules.Classify              [256, 5]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1444693 parameters, 1444693 gradients, 3.4 GFLOPs\n",
            "2023-03-15 03:43:11.863922: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-15 03:43:12.922173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-15 03:43:12.922328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-15 03:43:12.922351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 16.9MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      1/100     0.172G     0.2959          2        224: 100% 149/149 [00:14<00:00, 10.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 30.98it/s]\n",
            "                   all      0.537          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      2/100     0.262G     0.2719          2        224: 100% 149/149 [00:12<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 27.22it/s]\n",
            "                   all      0.537          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      3/100     0.264G     0.2707          2        224: 100% 149/149 [00:12<00:00, 12.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 34.19it/s]\n",
            "                   all      0.648          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      4/100     0.264G      0.269          2        224: 100% 149/149 [00:11<00:00, 13.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 17.41it/s]\n",
            "                   all      0.556          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      5/100     0.264G     0.2655          2        224: 100% 149/149 [00:10<00:00, 13.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.26it/s]\n",
            "                   all      0.648          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      6/100     0.264G     0.2616          2        224: 100% 149/149 [00:12<00:00, 12.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 37.14it/s]\n",
            "                   all      0.389          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      7/100     0.264G     0.2437          2        224: 100% 149/149 [00:12<00:00, 12.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 51.76it/s]\n",
            "                   all      0.778          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      8/100     0.264G     0.2328          2        224: 100% 149/149 [00:12<00:00, 12.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 51.13it/s]\n",
            "                   all      0.389          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      9/100     0.264G     0.2195          2        224: 100% 149/149 [00:11<00:00, 12.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 29.97it/s]\n",
            "                   all      0.278          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     10/100     0.264G     0.2053          2        224: 100% 149/149 [00:11<00:00, 12.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 24.03it/s]\n",
            "                   all      0.778          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     11/100     0.264G     0.2055          2        224: 100% 149/149 [00:11<00:00, 12.61it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 32.91it/s]\n",
            "                   all      0.537          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     12/100     0.264G     0.2024          2        224: 100% 149/149 [00:11<00:00, 12.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 37.16it/s]\n",
            "                   all      0.704          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     13/100     0.264G     0.1909          2        224: 100% 149/149 [00:11<00:00, 13.52it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 55.27it/s]\n",
            "                   all      0.556          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     14/100     0.264G     0.1858          2        224: 100% 149/149 [00:10<00:00, 13.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 33.06it/s]\n",
            "                   all      0.722          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     15/100     0.264G      0.184          2        224: 100% 149/149 [00:11<00:00, 13.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 25.41it/s]\n",
            "                   all      0.778          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     16/100     0.264G     0.1826          2        224: 100% 149/149 [00:10<00:00, 13.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 33.67it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     17/100     0.264G      0.183          2        224: 100% 149/149 [00:10<00:00, 13.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 54.68it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     18/100     0.264G     0.1746          2        224: 100% 149/149 [00:10<00:00, 14.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 17.95it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     19/100     0.264G     0.1733          2        224: 100% 149/149 [00:09<00:00, 15.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 29.10it/s]\n",
            "                   all      0.778          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     20/100     0.264G     0.1708          2        224: 100% 149/149 [00:10<00:00, 13.59it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 24.60it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     21/100     0.264G     0.1711          2        224: 100% 149/149 [00:11<00:00, 13.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 31.04it/s]\n",
            "                   all      0.778          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     22/100     0.264G     0.1681          2        224: 100% 149/149 [00:10<00:00, 13.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.95it/s]\n",
            "                   all      0.741          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     23/100     0.264G     0.1658          2        224: 100% 149/149 [00:11<00:00, 13.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 35.86it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     24/100     0.264G     0.1642          2        224: 100% 149/149 [00:09<00:00, 14.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 16.22it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     25/100     0.264G     0.1613          2        224: 100% 149/149 [00:10<00:00, 14.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 59.90it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     26/100     0.264G     0.1599          2        224: 100% 149/149 [00:11<00:00, 13.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.92it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     27/100     0.264G      0.152          2        224: 100% 149/149 [00:11<00:00, 12.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 34.46it/s]\n",
            "                   all      0.741          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     28/100     0.264G     0.1512          2        224: 100% 149/149 [00:11<00:00, 13.08it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 23.40it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     29/100     0.264G     0.1558          2        224: 100% 149/149 [00:11<00:00, 13.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 54.10it/s]\n",
            "                   all      0.796          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     30/100     0.264G     0.1512          2        224: 100% 149/149 [00:09<00:00, 15.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 24.78it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     31/100     0.264G     0.1486          2        224: 100% 149/149 [00:10<00:00, 13.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 30.85it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     32/100     0.264G     0.1471          2        224: 100% 149/149 [00:11<00:00, 13.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 57.83it/s]\n",
            "                   all      0.796          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     33/100     0.264G     0.1387          2        224: 100% 149/149 [00:12<00:00, 12.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.15it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     34/100     0.264G     0.1469          2        224: 100% 149/149 [00:11<00:00, 12.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.54it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     35/100     0.264G     0.1452          2        224: 100% 149/149 [00:11<00:00, 12.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 27.96it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     36/100     0.264G     0.1413          2        224: 100% 149/149 [00:10<00:00, 14.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.08it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     37/100     0.264G     0.1382          2        224: 100% 149/149 [00:10<00:00, 14.46it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 51.93it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     38/100     0.264G     0.1325          2        224: 100% 149/149 [00:11<00:00, 12.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 25.35it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     39/100     0.264G     0.1323          2        224: 100% 149/149 [00:11<00:00, 13.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 53.95it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     40/100     0.264G     0.1318          2        224: 100% 149/149 [00:11<00:00, 12.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 44.68it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     41/100     0.264G     0.1327          2        224: 100% 149/149 [00:11<00:00, 12.70it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 39.13it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     42/100     0.264G     0.1244          2        224: 100% 149/149 [00:11<00:00, 13.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 53.56it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     43/100     0.264G     0.1282          2        224: 100% 149/149 [00:09<00:00, 15.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 30.78it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     44/100     0.264G      0.125          2        224: 100% 149/149 [00:11<00:00, 13.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 28.47it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     45/100     0.264G     0.1235          2        224: 100% 149/149 [00:11<00:00, 13.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 54.66it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     46/100     0.264G     0.1087          2        224: 100% 149/149 [00:11<00:00, 13.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 21.40it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     47/100     0.264G     0.1195          2        224: 100% 149/149 [00:11<00:00, 13.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 47.25it/s]\n",
            "                   all      0.685          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     48/100     0.264G     0.1208          2        224: 100% 149/149 [00:11<00:00, 13.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 54.16it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     49/100     0.264G     0.1222          2        224: 100% 149/149 [00:09<00:00, 15.18it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 23.65it/s]\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     50/100     0.264G     0.1138          2        224: 100% 149/149 [00:11<00:00, 13.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 31.80it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     51/100     0.264G     0.1207          2        224: 100% 149/149 [00:11<00:00, 13.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 55.68it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     52/100     0.264G     0.1133          2        224: 100% 149/149 [00:11<00:00, 13.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.18it/s]\n",
            "                   all      0.759          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     53/100     0.264G     0.1197          2        224: 100% 149/149 [00:11<00:00, 13.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.78it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     54/100     0.264G     0.1046          2        224: 100% 149/149 [00:11<00:00, 13.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.10it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     55/100     0.264G     0.1119          2        224: 100% 149/149 [00:09<00:00, 15.18it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 25.62it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     56/100     0.264G     0.1071          2        224: 100% 149/149 [00:11<00:00, 13.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 17.17it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     57/100     0.264G      0.107          2        224: 100% 149/149 [00:11<00:00, 13.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 38.92it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     58/100     0.264G     0.1035          2        224: 100% 149/149 [00:11<00:00, 13.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 24.59it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     59/100     0.264G    0.09939          2        224: 100% 149/149 [00:11<00:00, 13.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 21.43it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     60/100     0.264G    0.09827          2        224: 100% 149/149 [00:10<00:00, 13.74it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 17.17it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     61/100     0.264G    0.09715          2        224: 100% 149/149 [00:10<00:00, 14.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 54.73it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     62/100     0.264G    0.09325          2        224: 100% 149/149 [00:11<00:00, 13.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 53.29it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     63/100     0.264G     0.0967          2        224: 100% 149/149 [00:11<00:00, 13.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 43.61it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     64/100     0.264G    0.09998          2        224: 100% 149/149 [00:11<00:00, 13.29it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 40.23it/s]\n",
            "                   all      0.722          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     65/100     0.264G    0.08892          2        224: 100% 149/149 [00:11<00:00, 12.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.93it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     66/100     0.264G    0.09364          2        224: 100% 149/149 [00:11<00:00, 12.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.99it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     67/100     0.264G    0.08667          2        224: 100% 149/149 [00:10<00:00, 13.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 27.10it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     68/100     0.264G    0.09061          2        224: 100% 149/149 [00:11<00:00, 13.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 35.86it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     69/100     0.264G    0.09277          2        224: 100% 149/149 [00:11<00:00, 12.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.45it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     70/100     0.264G    0.08915          2        224: 100% 149/149 [00:12<00:00, 12.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 47.63it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     71/100     0.264G    0.08995          2        224: 100% 149/149 [00:12<00:00, 12.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 33.75it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     72/100     0.264G    0.08515          2        224: 100% 149/149 [00:12<00:00, 12.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.94it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     73/100     0.264G    0.09154          2        224: 100% 149/149 [00:12<00:00, 12.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.14it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     74/100     0.264G    0.07847          2        224: 100% 149/149 [00:12<00:00, 12.31it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 27.10it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     75/100     0.264G    0.08391          2        224: 100% 149/149 [00:11<00:00, 12.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 16.53it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     76/100     0.264G    0.08364          2        224: 100% 149/149 [00:10<00:00, 13.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 23.21it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     77/100     0.264G    0.08722          2        224: 100% 149/149 [00:11<00:00, 12.63it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.49it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     78/100     0.264G    0.08162          2        224: 100% 149/149 [00:12<00:00, 12.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.14it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     79/100     0.264G    0.07975          2        224: 100% 149/149 [00:11<00:00, 12.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 33.50it/s]\n",
            "                   all      0.796          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     80/100     0.264G     0.0818          2        224: 100% 149/149 [00:11<00:00, 12.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 36.67it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     81/100     0.264G    0.08163          2        224: 100% 149/149 [00:12<00:00, 12.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 50.40it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     82/100     0.264G    0.08007          2        224: 100% 149/149 [00:12<00:00, 12.26it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 51.51it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     83/100     0.264G    0.07943          2        224: 100% 149/149 [00:12<00:00, 12.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 26.59it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     84/100     0.264G    0.07959          2        224: 100% 149/149 [00:12<00:00, 12.26it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 19.49it/s]\n",
            "                   all       0.87          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     85/100     0.264G    0.07833          2        224: 100% 149/149 [00:11<00:00, 13.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.34it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     86/100     0.264G    0.07237          2        224: 100% 149/149 [00:11<00:00, 13.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 23.94it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     87/100     0.264G     0.0703          2        224: 100% 149/149 [00:12<00:00, 12.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 35.85it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     88/100     0.264G    0.06936          2        224: 100% 149/149 [00:12<00:00, 12.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 52.90it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     89/100     0.264G    0.07047          2        224: 100% 149/149 [00:12<00:00, 12.31it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 50.85it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     90/100     0.264G    0.06522          2        224: 100% 149/149 [00:11<00:00, 12.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 51.15it/s]\n",
            "                   all      0.944          1\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     91/100     0.264G    0.06837          2        224: 100% 149/149 [00:12<00:00, 12.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 35.57it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     92/100     0.264G    0.06572          2        224: 100% 149/149 [00:12<00:00, 12.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 22.68it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     93/100     0.264G    0.06425          2        224: 100% 149/149 [00:12<00:00, 12.31it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 16.11it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     94/100     0.264G    0.06726          2        224: 100% 149/149 [00:10<00:00, 14.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 30.42it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     95/100     0.264G     0.0637          2        224: 100% 149/149 [00:10<00:00, 14.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.66it/s]\n",
            "                   all      0.944          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     96/100     0.264G    0.06349          2        224: 100% 149/149 [00:10<00:00, 13.61it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 42.44it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     97/100     0.264G    0.05927          2        224: 100% 149/149 [00:11<00:00, 13.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 53.77it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     98/100     0.264G    0.06427          2        224: 100% 149/149 [00:10<00:00, 13.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 57.06it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     99/100     0.264G    0.06046          2        224: 100% 149/149 [00:09<00:00, 14.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 18.89it/s]\n",
            "                   all      0.907          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    100/100     0.264G    0.05704          2        224: 100% 149/149 [00:10<00:00, 13.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00, 40.50it/s]\n",
            "                   all      0.889          1\n",
            "\n",
            "100 epochs completed in 0.323 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=val model=runs/classify/train/weights/best.pt data={dataset.location}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkzAqgk-zsDN",
        "outputId": "902f8f44-99ed-4208-937d-ad7299858cf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
            "               classes   top1_acc   top5_acc: 100% 4/4 [00:00<00:00, 29.89it/s]\n",
            "                   all      0.889          1\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=predict model=runs/classify/train/weights/best.pt conf=0.25 source={dataset.location}/test/Bengin save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDGGW8YC0OL-",
        "outputId": "859760b6-dc68-4145-9787-8af849aeaee6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 16.8MB/s]\n",
            "image 1/2 /content/Lung-cancer-detection-1/test/Bengin/Bengin-case-64-_jpg.rf.dba08dd56fbd50da40203e8b14d85f2b.jpg: 224x224 Bengin case 0.97, Normal case 0.03, Bengin case Malignant case 0.00, Malignant case Normal case 0.00, Malignant case 0.00, 5.4ms\n",
            "image 2/2 /content/Lung-cancer-detection-1/test/Bengin/Bengin-case-70-_jpg.rf.9c95114e1a847ce43afb476db08cdb60.jpg: 224x224 Malignant case 0.35, Bengin case 0.27, Bengin case Malignant case 0.21, Normal case 0.16, Malignant case Normal case 0.01, 4.8ms\n",
            "Speed: 0.3ms preprocess, 5.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}